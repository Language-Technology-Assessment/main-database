---
# Thank you for contributing!
# In filling out this yaml file, please follow the criteria as described here:
# https://osai-index.eu/contribute

# You're free to build on this work and reuse the data. It is licensed under CC-BY 4.0, with the
# stipulation that attribution should come in the form of a link to https://osai-index.eu/
# and a citation to the peer-reviewed paper in which the dataset & criteria were published:

# Liesenfeld, A. and Dingemanse, M., 2024. Rethinking open source generative AI: open-washing and the EU AI Act. In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (pp. 1774-1787).

# Organization tags:
# - National origin: United States
# - Contributor type: Non-academic (Company)

system:
    name: NeuralChat
    link: https://huggingface.co/Intel/neural-chat-7b-v3-3
    type: text 
    performanceclass: full
    basemodelname: Mistral-7B-v0.1
    endmodelname: Neural-Chat-7B-v3.3
    endmodellicense: Apache 2.0
    releasedate: 2023-11
    notes: Mistral-based Orca-finetuned chat model.

org:
    name: Intel
    link: https://huggingface.co/Intel
    notes: Intel, a major chip manufacturer.

# availability:
datasources_basemodel:
    class: closed
    link:
    notes: Mistral has not disclosed anything about its training data

datasources_endmodel:
    class: open
    link: ["https://huggingface.co/datasets/Open-Orca/SlimOrca", "https://huggingface.co/datasets/meta-math/MetaMathQA", "https://huggingface.co/datasets/Intel/orca_dpo_pairs"]
    notes: Dataset used for fine-tuning is shared and available

weights_basemodel:
    class: open
    link: https://huggingface.co/mistralai/Mistral-7B-v0.1
    notes: Based on Mistral 7B 0.1
    
weights_endmodel:
    class: open
    link: https://huggingface.co/Intel/neural-chat-7b-v3-3
    notes: Finetuned model made openly available by Intel.

trainingcode:
    class: partial
    link: https://github.com/intel/intel-extension-for-transformers/tree/main/intel_extension_for_transformers/neural_chat/examples/finetuning/finetune_neuralchat_v3
    notes: Mistral base model is not open, but repo gives sample code for fine-tuning based on that.

# documentation:
code:
    class: partial
    link: https://github.com/intel/intel-extension-for-transformers/tree/main/intel_extension_for_transformers/neural_chat/examples/finetuning/finetune_neuralchat_v3#how-to-train-intelneural-chat-7b-v3-1-on-intel-gaudi2
    notes: Mistral remains closed so only documentation pertains to fine-tuning steps, but that code is quite well documented, so partial.

hardware_architecture:
    class: partial
    link: https://medium.com/intel-analytics-software/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3
    notes: Described on HuggingFace model card and a Medium post.

preprint:
    class: closed
    link: https://medium.com/intel-analytics-software/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3
    notes: A medium post is apparently the only scientific documentation of this model.

paper:
    class: closed
    link:
    notes: No peer-reviewed paper found.

modelcard:
    class: partial
    link: https://huggingface.co/Intel/neural-chat-7b-v3-3
    notes: Model card provides limited information in desired categories. 

datasheet:
    class: partial
    link: ["https://huggingface.co/datasets/Open-Orca/SlimOrca", "https://huggingface.co/datasets/meta-math/MetaMathQA", "https://huggingface.co/datasets/Intel/orca_dpo_pairs"]
    notes: Data sheets contain differing amounts of information.

# access:
package:
    class: open
    link: https://ollama.com/library/neural-chat
    notes: Model available on Ollama.

api:
    class: closed
    link: 
    notes: Provided through HuggingFace but model too large to run via inference API, local deployment or paid access needed 
    metaprompt: closed

licenses:
    class: open
    link: https://huggingface.co/Intel/neural-chat-7b-v3-1#fp32-inference-with-transformers
    notes: Apache-2.0, an OSI-approved license.

