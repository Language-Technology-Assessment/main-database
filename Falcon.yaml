---
# Thank you for contributing!
# In filling out this yaml file, please follow the criteria as described here: 
# https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io/tree/main/projects#criteria

# You're free to build on this work and reuse the data. It is licensed under CC-BY 4.0, with the
# stipulation that attribution should come in the form of a link to http://opening-up-chatgpt.github.io
# and a citation to the paper in which the initial dataset & criteria were published:

# Liesenfeld, Andreas, Alianda Lopez, and Mark Dingemanse. 2023. “Opening up ChatGPT: Tracking Openness, Transparency, and Accountability in Instruction-Tuned Text Generators.” In CUI '23: Proceedings of the 5th International Conference on Conversational User Interfaces. July 19-21, Eindhoven. doi: 10.1145/3571884.3604316 

system:
    name: Falcon
    link: https://huggingface.co/tiiuae/Falcon3-10B-Instruct
    type: text
    performanceclass: full
    basemodelname: Falcon3-10B-Base
    endmodelname: Falcon3-10B-Instruct
    endmodellicense: Falcon-LLM-License
    releasedate: 2023-05
    notes: Open foundation model.

org:
    name: Technology Innovation Institute
    link: https://falconllm.tii.ae
    notes: The Technology Innovation Institute, a research center. Part of the Abu Dhabi Government’s Advanced Technology Research Council (ATRC).

# availability:
datasources_basemodel:
    class: partial
    link: https://huggingface.co/datasets/tiiuae/falcon-refinedweb
    notes: From the documentation 'The key ingredient for the high quality of the Falcon models is their training data, predominantly based (>80%) on RefinedWeb — a novel massive web dataset based on CommonCrawl' (https://huggingface.co/blog/falcon). However, only a small sample is made available.

datasources_endmodel:
    class: partial
    link: https://github.com/project-baize/baize-chatbot
    notes: RL data inherited from Baize but provenance not well-documented. From the documentation 'Falcon-40B-Instruct was finetuned on a 150M tokens from Baize mixed with 5% of RefinedWeb data.'

weights_basemodel:
    class: open
    link: https://huggingface.co/tiiuae/falcon-40b-instruct/tree/main
    notes: Model weights available through HuggingFace library

weights_endmodel:
    class: closed
    link: https://github.com/project-baize/baize-chatbot#v1
    notes: No RL weights or checkpoints made available

trainingcode:
    class: closed
    link: https://huggingface.co/tiiuae/falcon-40b-instruct
    notes: No source code shared, even though the term "open source" is used.

# documentation
code:
    class: closed
    link:
    notes: No source code found, therefore no documentation found.

hardware_architecture:
    class: partial
    link:
    notes: Architecture sketched on HuggingFace as "Falcon-40B-Instruct is a 40B parameters causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize."

preprint:
    class: open
    link: 
        - https://arxiv.org/abs/2306.01116
        - https://arxiv.org/abs/2311.16867
    notes: First preprint covers the creation and curation of RefinedWeb dataset, but not other aspects of the model. The second preprint provides more details about the model architecture, implementation, evaluation results, and limitations.

paper:
    class: closed
    link:
    notes: No peer-reviewed paper known.

modelcard:
    class: partial
    link: https://huggingface.co/tiiuae/falcon-40b-instruct
    notes: Model card on HuggingFace is mostly used to advertise the model, not to document its training and evaluation details.

datasheet:
    class: open
    link: https://arxiv.org/abs/2306.01116
    notes: The preprint on RefinedWeb dataset presents a datasheet in a section named "RefinedWeb Datasheet", which goes into quite a bit of detail on collection, preprocessing etc.

# access
package:
    class: closed
    link:
    notes: There is no package.

api:
    class: closed
    link: https://huggingface.co/tiiuae/falcon-40b-instruct
    notes: There is no API, and HuggingFace inference API is disabled for this model.
    metaprompt: closed

licenses:
    class: open
    link:
    notes: First release came with a legally murky license that was swiftly criticised and now generates a 404. Current documentation 'Falcon-40B-Instruct is made available under the Apache 2.0 license.'
